[2025-10-05 05:25:40,748][root][INFO] - Configuration: experiment:
  data_path: ../data
  checkpoint_dir: ../checkpoints
  models:
  - 'inf'
  row_fraction: 1.0
  num_targets: 424
  filter_features: false
  optuna:
    direction: minimize
    n_trials: 2
    n_jobs: 2
model:
  model_type: default
  model_class: default
  trainer_class: default
  params:
    input_size: 1672
    output_size: 424
    input_len: 64
    output_len: 5
    batch_size: 16
    hidden_size: 128
    num_layers: 2
    dropout: 0.1
    epochs: 10
    patience: 5
    channels: 64
    blocks: 3
    kernel_size: 5
    num_conv_layers: 2
    tcn_kernel: 3
    decom_kernel_size: 25
    top_k_modes: 5
    nhead: 8
    dim_feedforward: 512
    weight_decay: 0.001
    scheduler_patience: 5
    scheduler_factor: 0.5
    clip_grad_norm: 1.0
    partially_finite_target: false
  lr: 0.001
  optimizer: AdamW
  lr_policy: constant

[2025-10-05 05:25:40,750][root][INFO] - Set random seed to 42 for reproducibility.
[2025-10-05 05:25:40,750][root][INFO] - CUDA version: 12.1
[2025-10-05 05:25:40,785][root][INFO] - Device count: 1
[2025-10-05 05:25:40,786][root][INFO] - Device name: NVIDIA GeForce RTX 4060 Laptop GPU
[2025-10-05 05:25:40,885][root][INFO] - Loading train.csv from ../data/train.csv
[2025-10-05 05:25:40,964][root][INFO] - Loading train_labels.csv from ../data/train_labels.csv
[2025-10-05 05:25:41,085][root][INFO] - Loading target_pairs.csv from ../data/target_pairs.csv
[2025-10-05 05:25:41,252][root][INFO] - X_full NaNs after imputation: 0
[2025-10-05 05:25:41,252][root][INFO] - Y_full NaNs before imputation: 0
[2025-10-05 05:25:41,254][root][INFO] - Y_full NaNs after imputation: 0
[2025-10-05 05:25:41,254][root][INFO] - X_full feature count: 1671
[2025-10-05 05:25:41,262][root][INFO] - Data loaded: X_full_np shape=(1917, 1671), Y_full_np shape=(1917, 424)
[2025-10-05 05:25:41,262][root][INFO] - Raw data shapes: X=(1917, 1671), Y=(1917, 424)
[2025-10-05 05:25:41,262][root][INFO] - Sample batch shapes: X=(64, 1671), Y=(64, 424)
[2025-10-05 05:25:41,737][root][INFO] - Trial 2 started with params: {'input_size': 1671, 'output_size': 424, 'output_len': 5, 'input_len': 32, 'label_len': 16, 'hidden_size': 128, 'num_layers': 4, 'd_layers': 2, 'nhead': 8, 'dim_feedforward': 1792, 'dropout': 0.1, 'batch_size': 32, 'attn': 'prob', 'distil': True}, lr=1.608991319802787e-05, optimizer=AdamW, lr_policy=onecycle
[2025-10-05 05:25:42,037][root][INFO] - Performed memory cleaning.
[2025-10-05 05:25:42,127][root][INFO] - Trial 3 started with params: {'input_size': 1671, 'output_size': 424, 'output_len': 5, 'input_len': 64, 'label_len': 64, 'hidden_size': 128, 'num_layers': 2, 'd_layers': 3, 'nhead': 8, 'dim_feedforward': 2048, 'dropout': 0.25, 'batch_size': 64, 'attn': 'prob', 'distil': True}, lr=0.0002531255764710957, optimizer=Adam, lr_policy=clr
[2025-10-05 05:25:42,412][root][INFO] - GPU Memory: 1.06 GB used out of 8.00 GB
[2025-10-05 05:25:42,412][root][INFO] - Performed memory cleaning.
[2025-10-05 05:25:42,412][root][INFO] - GPU Memory: 1.06 GB used out of 8.00 GB
[2025-10-05 05:25:42,416][root][INFO] - Trial 2: X_raw shape=(1917, 1671), Y_raw shape=(1917, 424), NaNs X=0, Y=0
[2025-10-05 05:25:42,416][root][INFO] - Trial 3: X_raw shape=(1917, 1671), Y_raw shape=(1917, 424), NaNs X=0, Y=0
[2025-10-05 05:25:42,416][root][INFO] - Building Informer datasets with input_len=32, output_len=5, label_len=16, use_time_feats=True
[2025-10-05 05:25:42,416][root][INFO] - Building Informer datasets with input_len=64, output_len=5, label_len=64, use_time_feats=True
[2025-10-05 05:25:42,668][root][INFO] - WindowDataset created: Xw shape=(1881, 32, 1671), Yw shape=(1881, 5, 424), invalid_windows: 0
[2025-10-05 05:25:43,189][root][INFO] - WindowDataset created: Xw shape=(1849, 64, 1671), Yw shape=(1849, 5, 424), invalid_windows: 0
[2025-10-05 05:25:45,321][root][INFO] - InformerWindowDataset created: Xw shape=(1881, 32, 1671), x_dec shape=(1881, 21, 424), Yw shape=(1881, 5, 424), mark_enc shape=(1881, 32, 128), invalid_windows=0
[2025-10-05 05:25:45,321][root][INFO] - Informer dataset created: X_enc shape=(1881, 32, 1671), x_dec shape=(1881, 21, 424), Y shape=(1881, 5, 424), mark_enc shape=(1881, 32, 128)
[2025-10-05 05:25:45,438][root][INFO] - Informer DataLoaders created: train=1411, val=282, test=188
[2025-10-05 05:25:45,438][root][INFO] - Trial 2: Creating InTrainer with device=cuda
[2025-10-05 05:25:45,438][root][INFO] - InTrainer initialized with model_kwargs: {'input_size': 1671, 'enc_in': 1671, 'dec_in': 424, 'c_out': 424, 'seq_len': 32, 'label_len': 16, 'out_len': 5, 'd_model': 128, 'n_heads': 8, 'e_layers': 4, 'd_layers': 2, 'd_ff': 1792, 'dropout': 0.1, 'attn': 'prob', 'embed': 'fixed', 'freq': 'd', 'activation': 'gelu', 'distil': True, 'device': 'cuda'}
[2025-10-05 05:25:45,508][root][ERROR] - Trial 2 failed: FullAttention.__init__() got an unexpected keyword argument 'factor'
Traceback (most recent call last):
  File "/root/vscode/portfolio/mitsui_2025/src/study.py", line 200, in objective_informer
    trainer = trainer_class(train_cfg)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/trainer.py", line 637, in __init__
    model = InForecaster(**model_kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/models.py", line 1604, in __init__
    [
  File "/root/vscode/portfolio/mitsui_2025/src/models.py", line 1608, in <listcomp>
    AttentionLayer(FullAttention(False, factor=10, attention_dropout=dropout, output_attention=False),
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: FullAttention.__init__() got an unexpected keyword argument 'factor'

[2025-10-05 05:25:45,786][root][INFO] - GPU Memory: 1.06 GB used out of 8.00 GB
[2025-10-05 05:25:46,043][root][INFO] - Performed memory cleaning.
[2025-10-05 05:25:46,748][root][INFO] - InformerWindowDataset created: Xw shape=(1849, 64, 1671), x_dec shape=(1849, 69, 424), Yw shape=(1849, 5, 424), mark_enc shape=(1849, 64, 128), invalid_windows=0
[2025-10-05 05:25:46,757][root][INFO] - Informer dataset created: X_enc shape=(1849, 64, 1671), x_dec shape=(1849, 69, 424), Y shape=(1849, 5, 424), mark_enc shape=(1849, 64, 128)
[2025-10-05 05:25:46,989][root][INFO] - Informer DataLoaders created: train=1388, val=277, test=184
[2025-10-05 05:25:46,989][root][INFO] - Trial 3: Creating InTrainer with device=cuda
[2025-10-05 05:25:46,989][root][INFO] - InTrainer initialized with model_kwargs: {'input_size': 1671, 'enc_in': 1671, 'dec_in': 424, 'c_out': 424, 'seq_len': 64, 'label_len': 64, 'out_len': 5, 'd_model': 128, 'n_heads': 8, 'e_layers': 2, 'd_layers': 3, 'd_ff': 2048, 'dropout': 0.25, 'attn': 'prob', 'embed': 'fixed', 'freq': 'd', 'activation': 'gelu', 'distil': True, 'device': 'cuda'}
[2025-10-05 05:25:46,996][root][ERROR] - Trial 3 failed: FullAttention.__init__() got an unexpected keyword argument 'factor'
Traceback (most recent call last):
  File "/root/vscode/portfolio/mitsui_2025/src/study.py", line 200, in objective_informer
    trainer = trainer_class(train_cfg)
              ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/trainer.py", line 637, in __init__
    model = InForecaster(**model_kwargs)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/models.py", line 1604, in __init__
    [
  File "/root/vscode/portfolio/mitsui_2025/src/models.py", line 1608, in <listcomp>
    AttentionLayer(FullAttention(False, factor=10, attention_dropout=dropout, output_attention=False),
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: FullAttention.__init__() got an unexpected keyword argument 'factor'

[2025-10-05 05:25:47,313][root][INFO] - GPU Memory: 1.06 GB used out of 8.00 GB
[2025-10-05 05:25:47,584][root][INFO] - Performed memory cleaning.
[2025-10-05 05:25:47,607][root][WARNING] - No completed trials for INF. All trials were pruned or failed. Trials: 4
[2025-10-05 05:25:47,608][root][INFO] - Trial states: [2, 2, 2, 2]
