[2025-10-04 18:35:30,916][root][INFO] - Configuration: experiment:
  data_path: ../data
  checkpoint_dir: ../checkpoints
  models:
  - fed
  row_fraction: 1.0
  num_targets: 424
  filter_features: false
  optuna:
    direction: minimize
    n_trials: 2
    n_jobs: 2
model:
  model_type: default
  model_class: default
  trainer_class: default
  params:
    input_size: 1672
    output_size: 424
    input_len: 64
    output_len: 5
    batch_size: 16
    hidden_size: 128
    num_layers: 2
    dropout: 0.1
    epochs: 10
    patience: 5
    channels: 64
    blocks: 3
    kernel_size: 5
    num_conv_layers: 2
    tcn_kernel: 3
    decom_kernel_size: 25
    top_k_modes: 5
    nhead: 8
    dim_feedforward: 512
    weight_decay: 0.001
    scheduler_patience: 5
    scheduler_factor: 0.5
    clip_grad_norm: 1.0
    partially_finite_target: false
  lr: 0.001
  optimizer: Adam
  lr_policy: constant

[2025-10-04 18:35:30,917][root][INFO] - Set random seed to 42 for reproducibility.
[2025-10-04 18:35:30,918][root][INFO] - Loading train.csv from ../data/train.csv
[2025-10-04 18:35:30,996][root][INFO] - Loading train_labels.csv from ../data/train_labels.csv
[2025-10-04 18:35:31,099][root][INFO] - Loading target_pairs.csv from ../data/target_pairs.csv
[2025-10-04 18:35:31,242][root][INFO] - X_full NaNs after imputation: 0
[2025-10-04 18:35:31,242][root][INFO] - Y_full NaNs before imputation: 0
[2025-10-04 18:35:31,243][root][INFO] - Y_full NaNs after imputation: 0
[2025-10-04 18:35:31,243][root][INFO] - X_full feature count: 1671
[2025-10-04 18:35:31,254][root][INFO] - Data loaded: X_full_np shape=(1917, 1671), Y_full_np shape=(1917, 424)
[2025-10-04 18:35:31,254][root][INFO] - Raw data shapes: X=(1917, 1671), Y=(1917, 424)
[2025-10-04 18:35:31,254][root][INFO] - Sample batch shapes: X=(64, 1671), Y=(64, 424)
[2025-10-04 18:35:31,709][root][INFO] - Trial 4 started with params: {'input_size': 1671, 'output_size': 424, 'output_len': 5, 'input_len': 48, 'hidden_size': 224, 'num_layers': 6, 'batch_size': 32, 'dropout': 0.5, 'decom_kernel_size': 10, 'top_k_modes': 7, 'nhead': 16, 'dim_feedforward': 1024}, lr=0.00029292738497147696, optimizer=Adam, lr_policy=onecycle
[2025-10-04 18:35:32,019][root][INFO] - Performed memory cleaning.
[2025-10-04 18:35:32,086][root][INFO] - Trial 5 started with params: {'input_size': 1671, 'output_size': 424, 'output_len': 5, 'input_len': 48, 'hidden_size': 144, 'num_layers': 1, 'batch_size': 32, 'dropout': 0.0, 'decom_kernel_size': 45, 'top_k_modes': 4, 'nhead': 8, 'dim_feedforward': 960}, lr=0.00012823653444767337, optimizer=AdamW, lr_policy=clr
[2025-10-04 18:35:32,360][root][INFO] - GPU Memory: 1.06 GB used out of 8.00 GB
[2025-10-04 18:35:32,360][root][INFO] - Performed memory cleaning.
[2025-10-04 18:35:32,361][root][INFO] - GPU Memory: 1.06 GB used out of 8.00 GB
[2025-10-04 18:35:32,365][root][INFO] - Trial 5: X_raw NaNs=0, Y_raw NaNs=0, input_size=1671
[2025-10-04 18:35:32,366][root][INFO] - Trial 4: X_raw NaNs=0, Y_raw NaNs=0, input_size=1671
[2025-10-04 18:35:32,690][root][INFO] - WindowDataset created: Xw shape=(1865, 48, 1671), Yw shape=(1865, 5, 424), invalid_windows: 0
[2025-10-04 18:35:32,690][root][INFO] - Trial 4 windowed shapes: Xw=(1865, 48, 1671), Yw=(1865, 5, 424)
[2025-10-04 18:35:32,691][root][INFO] - WindowDataset created: Xw shape=(1865, 48, 1671), Yw shape=(1865, 5, 424), invalid_windows: 0
[2025-10-04 18:35:32,691][root][INFO] - Trial 5 windowed shapes: Xw=(1865, 48, 1671), Yw=(1865, 5, 424)
[2025-10-04 18:35:32,839][root][INFO] - Creating trainer with device=cuda
[2025-10-04 18:35:32,842][root][INFO] - Creating trainer with device=cuda
[2025-10-04 18:35:32,857][root][INFO] - Trainer initialized with device=cuda
[2025-10-04 18:35:32,857][root][INFO] - Trial 5: Training data shapes: X=torch.Size([1865, 48, 1671]), Y=torch.Size([1865, 5, 424])
[2025-10-04 18:35:32,914][root][INFO] - Trainer initialized with device=cuda
[2025-10-04 18:35:32,915][root][INFO] - Trial 4: Training data shapes: X=torch.Size([1865, 48, 1671]), Y=torch.Size([1865, 5, 424])
[2025-10-04 18:35:34,378][root][ERROR] - Trial 4 failed: The size of tensor a (57) must match the size of tensor b (56) at non-singleton dimension 2
Traceback (most recent call last):
  File "/root/vscode/portfolio/mitsui_2025/src/study.py", line 223, in objective
    val_loss, loss_tracker = trainer.train(train_tensors[0].numpy(), train_tensors[1].numpy())
                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/trainer.py", line 150, in train
    train_loss = self.train_one_epoch(train_loader)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/trainer.py", line 87, in train_one_epoch
    pred = self.model(xb).squeeze(1)  # (B, num_targets)
           ^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/mitsui/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/mitsui/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/models.py", line 1013, in forward
    trend, seasonal = self.decomposer(x)  # Both (B, T, F)
                      ^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/mitsui/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/anaconda3/envs/mitsui/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/vscode/portfolio/mitsui_2025/src/models.py", line 873, in forward
    seasonal_trans = x_trans - trend_trans  # (B, F, T)
                     ~~~~~~~~^~~~~~~~~~~~~
RuntimeError: The size of tensor a (57) must match the size of tensor b (56) at non-singleton dimension 2

[2025-10-04 18:35:34,666][root][INFO] - GPU Memory: 1.27 GB used out of 8.00 GB
[2025-10-04 18:35:34,926][root][INFO] - Performed memory cleaning.
[2025-10-04 18:35:36,592][root][INFO] - Model: FED, Epoch 1/25: Train Loss=0.008890, Val Loss=0.009804
[2025-10-04 18:35:37,271][root][INFO] - Model: FED, Epoch 2/25: Train Loss=0.002609, Val Loss=0.007137
[2025-10-04 18:35:37,967][root][INFO] - Model: FED, Epoch 3/25: Train Loss=0.001631, Val Loss=0.005992
[2025-10-04 18:35:38,674][root][INFO] - Model: FED, Epoch 4/25: Train Loss=0.001238, Val Loss=0.005478
[2025-10-04 18:35:39,376][root][INFO] - Model: FED, Epoch 5/25: Train Loss=0.001147, Val Loss=0.005290
[2025-10-04 18:35:40,083][root][INFO] - Model: FED, Epoch 6/25: Train Loss=0.001119, Val Loss=0.005184
[2025-10-04 18:35:40,784][root][INFO] - Model: FED, Epoch 7/25: Train Loss=0.001105, Val Loss=0.004973
[2025-10-04 18:35:41,491][root][INFO] - Model: FED, Epoch 8/25: Train Loss=0.001095, Val Loss=0.004800
[2025-10-04 18:35:42,205][root][INFO] - Model: FED, Epoch 9/25: Train Loss=0.001088, Val Loss=0.004752
[2025-10-04 18:35:42,918][root][INFO] - Model: FED, Epoch 10/25: Train Loss=0.001082, Val Loss=0.004627
[2025-10-04 18:35:43,641][root][INFO] - Model: FED, Epoch 11/25: Train Loss=0.001079, Val Loss=0.004665
[2025-10-04 18:35:44,362][root][INFO] - Model: FED, Epoch 12/25: Train Loss=0.001074, Val Loss=0.004435
[2025-10-04 18:35:45,075][root][INFO] - Model: FED, Epoch 13/25: Train Loss=0.001071, Val Loss=0.004370
[2025-10-04 18:35:45,791][root][INFO] - Model: FED, Epoch 14/25: Train Loss=0.001068, Val Loss=0.004343
[2025-10-04 18:35:46,511][root][INFO] - Model: FED, Epoch 15/25: Train Loss=0.001065, Val Loss=0.004345
[2025-10-04 18:35:47,231][root][INFO] - Model: FED, Epoch 16/25: Train Loss=0.001063, Val Loss=0.004256
[2025-10-04 18:35:47,958][root][INFO] - Model: FED, Epoch 17/25: Train Loss=0.001062, Val Loss=0.004207
[2025-10-04 18:35:48,681][root][INFO] - Model: FED, Epoch 18/25: Train Loss=0.001060, Val Loss=0.004308
[2025-10-04 18:35:49,399][root][INFO] - Model: FED, Epoch 19/25: Train Loss=0.001060, Val Loss=0.004285
[2025-10-04 18:35:50,117][root][INFO] - Model: FED, Epoch 20/25: Train Loss=0.001057, Val Loss=0.004174
[2025-10-04 18:35:50,828][root][INFO] - Model: FED, Epoch 21/25: Train Loss=0.001055, Val Loss=0.004189
[2025-10-04 18:35:51,536][root][INFO] - Model: FED, Epoch 22/25: Train Loss=0.001054, Val Loss=0.004132
[2025-10-04 18:35:52,247][root][INFO] - Model: FED, Epoch 23/25: Train Loss=0.001055, Val Loss=0.004233
[2025-10-04 18:35:52,968][root][INFO] - Model: FED, Epoch 24/25: Train Loss=0.001051, Val Loss=0.004079
[2025-10-04 18:35:53,688][root][INFO] - Model: FED, Epoch 25/25: Train Loss=0.001049, Val Loss=0.004073
[2025-10-04 18:35:53,789][root][INFO] - Saved best model to ../checkpoints/FED_trial5_20251004_183553.pt
[2025-10-04 18:35:54,224][root][INFO] - GPU Memory: 1.25 GB used out of 8.00 GB
[2025-10-04 18:35:54,494][root][INFO] - Performed memory cleaning.
[2025-10-04 18:35:54,606][root][INFO] - Best trial for FED: 5, value: 0.00407287228425237, params: {'batch_size': 32, 'input_len': 48, 'hidden_size': 144, 'num_layers': 1, 'dropout': 0.0, 'lr': 0.00012823653444767337, 'optimizer': 'AdamW', 'lr_policy': 'clr', 'decom_kernel_size': 45, 'top_k_modes': 4, 'nhead': 8, 'dim_feedforward': 960}
