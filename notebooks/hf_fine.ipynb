{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dbab57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/vscode/portfolio/mitsui_2025\n"
     ]
    }
   ],
   "source": [
    "# In your notebook/*.ipynb\n",
    "# Go up one level to the root directory\n",
    "%cd ..\n",
    "# Optional: change back to the notebook directory\n",
    "# %cd notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22503d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 01:35:25,861 - INFO - Loading train.csv from data/train.csv\n",
      "2025-10-02 01:35:25,943 - INFO - Loading train_labels.csv from data/train_labels.csv\n",
      "2025-10-02 01:35:26,049 - INFO - Loading target_pairs.csv from data/target_pairs.csv\n",
      "2025-10-02 01:35:26,193 - INFO - X_full NaNs after imputation: 0\n",
      "2025-10-02 01:35:26,193 - INFO - Y_full NaNs before imputation: 0\n",
      "2025-10-02 01:35:26,196 - INFO - Y_full NaNs after imputation: 0\n",
      "2025-10-02 01:35:26,196 - INFO - X_full feature count: 1671\n",
      "2025-10-02 01:35:26,204 - INFO - Data loaded: X_full_np shape=(1917, 1671), Y_full_np shape=(1917, 424)\n"
     ]
    }
   ],
   "source": [
    "# Since src folder is now 'packaged' by __init__.py\n",
    "# to import specific abc.py file, use: from src.abc import ~\n",
    "import logging \n",
    "import torch \n",
    "from src.dataprep import dataprep, WindowDataset\n",
    "from src.configs import TrainConfig\n",
    "\n",
    "\n",
    "data_preparer = dataprep(data_path='data')\n",
    "data_preparer.one_shot_prep()  # Loads prices, targets, imputes NaNs, adds staleness/missing masks\n",
    "X_raw = data_preparer.X_full_np  # (N_dates, 559 features)\n",
    "Y_raw = data_preparer.Y_full_np  # (N_dates, 424 targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a8e3f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 01:35:26,227 - INFO - Manual time features added: X_transformed shape (1917, 1675), Y_transformed shape (1917, 424)\n",
      "2025-10-02 01:35:26,227 - INFO - X_transformed shape: (1917, 1675), Y_transformed shape: (1917, 424)\n"
     ]
    }
   ],
   "source": [
    "# Define TrainConfig with conservative settings\n",
    "cfg = TrainConfig(\n",
    "    input_len=32,      # Smaller context length to reduce memory usage\n",
    "    output_len=1,      # One-step-ahead prediction\n",
    "    batch_size=16,     # Smaller batch size for stability\n",
    "    input_size=X_raw.shape[1],  # 559 features\n",
    "    output_size=Y_raw.shape[1],  # 424 targets\n",
    "    nhead=4,           # Fewer attention heads\n",
    "    dim_feedforward=256,  # Smaller feedforward dim\n",
    "    num_layers=1,      # Fewer layers\n",
    "    dropout=0.2        # Higher dropout for regularization\n",
    ")\n",
    "\n",
    "try:\n",
    "    X_transformed, Y_transformed = data_preparer.GluonTS_transform(cfg=cfg, model_type=['TSTP'])\n",
    "    logging.info(f\"X_transformed shape: {X_transformed.shape}, Y_transformed shape: {Y_transformed.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error in GluonTS_transform: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "347a20cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 01:35:26,237 - INFO - X_raw shape after preprocess_for_frequency: (1917, 1671)\n",
      "2025-10-02 01:35:26,243 - INFO - Manual time features added: X_transformed shape (1917, 1675), Y_transformed shape (1917, 424)\n",
      "2025-10-02 01:35:26,244 - INFO - X_transformed shape: (1917, 1675), Y_transformed shape: (1917, 424)\n",
      "2025-10-02 01:35:26,482 - INFO - WindowDataset created: Xw shape=(1885, 32, 1675), Yw shape=(1885, 1, 424), invalid_windows: 0\n",
      "2025-10-02 01:35:26,483 - INFO - Windowed shapes: Xw=(1885, 32, 1675), Yw=(1885, 1, 424)\n",
      "2025-10-02 01:35:26,618 - INFO - Dataset split: train=1415, val=282, test=188\n",
      "2025-10-02 01:35:26,626 - INFO - DataLoaders created successfully\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Optional: Add frequency-domain features (FFT)\n",
    "X_raw = data_preparer.preprocess_for_frequency(X_raw, use_fft=False)  # Set use_fft=True if desired\n",
    "logging.info(f\"X_raw shape after preprocess_for_frequency: {X_raw.shape}\")\n",
    "\n",
    "# Apply GluonTS transformation\n",
    "try:\n",
    "    X_transformed, Y_transformed = data_preparer.GluonTS_transform(cfg=cfg, model_type=['TSTP'])\n",
    "    logging.info(f\"X_transformed shape: {X_transformed.shape}, Y_transformed shape: {Y_transformed.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"GluonTS transformation failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create WindowDataset\n",
    "try:\n",
    "    dataset = WindowDataset(X_transformed, Y_transformed, input_len=cfg.input_len, output_len=cfg.output_len)\n",
    "    Xw, Yw = dataset.x, dataset.y\n",
    "    logging.info(f\"Windowed shapes: Xw={Xw.shape}, Yw={Yw.shape}\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"WindowDataset creation failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create TensorDataset and split\n",
    "from torch.utils.data import TensorDataset, DataLoader, random_split\n",
    "dataset = TensorDataset(\n",
    "    torch.tensor(Xw, dtype=torch.float32),\n",
    "    torch.tensor(Yw, dtype=torch.float32)\n",
    ")\n",
    "N = len(dataset)\n",
    "n_val = max(1, int(0.15 * N))\n",
    "n_test = max(1, int(0.1 * N))\n",
    "n_train = N - n_val - n_test\n",
    "logging.info(f\"Dataset split: train={n_train}, val={n_val}, test={n_test}\")\n",
    "\n",
    "try:\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, [n_train, n_val, n_test], generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "except Exception as e:\n",
    "    logging.error(f\"Dataset split failed: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=cfg.batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=cfg.batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=cfg.batch_size, shuffle=False)\n",
    "logging.info(\"DataLoaders created successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
